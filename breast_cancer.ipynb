{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd096e274fe2709b7bb279ad04311144474e6f198e9a711d8335d23a0c89fef7735",
   "display_name": "Python 3.8.5 64-bit ('Deeplearning': venv)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "source": [
    "Importing Dataset to dataframe \"data\" :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')\n"
   ]
  },
  {
   "source": [
    "Dropping unwanted columns having Nan Values :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['Unnamed: 32']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 2:].values\n",
    "y = data.iloc[:, 1].values\n",
    "\n",
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "y = labelencoder_X_1.fit_transform(y)\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)\n",
    "\n",
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "source": [
    "Artificial Neural Network Model Building"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.preprocessing import minmax_scale,StandardScaler\n",
    "from sklearn.metrics import classification_report,f1_score,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dropout , Dense"
   ]
  },
  {
   "source": [
    "Model Building :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units = 6, activation = 'relu')) #First hidden layer\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units = 6, activation = 'relu')) #Second hidden layer\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/70\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2322 - accuracy: 0.9414\n",
      "Epoch 2/70\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2272 - accuracy: 0.9414\n",
      "Epoch 3/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2217 - accuracy: 0.9395\n",
      "Epoch 4/70\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2164 - accuracy: 0.9414\n",
      "Epoch 5/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2125 - accuracy: 0.9395\n",
      "Epoch 6/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2071 - accuracy: 0.9414\n",
      "Epoch 7/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2038 - accuracy: 0.9375\n",
      "Epoch 8/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1984 - accuracy: 0.9414\n",
      "Epoch 9/70\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1945 - accuracy: 0.9434\n",
      "Epoch 10/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1908 - accuracy: 0.9414\n",
      "Epoch 11/70\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1873 - accuracy: 0.9434\n",
      "Epoch 12/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1840 - accuracy: 0.9434\n",
      "Epoch 13/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1802 - accuracy: 0.9434\n",
      "Epoch 14/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1766 - accuracy: 0.9473\n",
      "Epoch 15/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1737 - accuracy: 0.9473\n",
      "Epoch 16/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1711 - accuracy: 0.9473\n",
      "Epoch 17/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1677 - accuracy: 0.9473\n",
      "Epoch 18/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1653 - accuracy: 0.9492\n",
      "Epoch 19/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1622 - accuracy: 0.9492\n",
      "Epoch 20/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1600 - accuracy: 0.9492\n",
      "Epoch 21/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1580 - accuracy: 0.9512\n",
      "Epoch 22/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1546 - accuracy: 0.9512\n",
      "Epoch 23/70\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1527 - accuracy: 0.9512\n",
      "Epoch 24/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1512 - accuracy: 0.9512\n",
      "Epoch 25/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1480 - accuracy: 0.9512\n",
      "Epoch 26/70\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1465 - accuracy: 0.9551\n",
      "Epoch 27/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1441 - accuracy: 0.9551\n",
      "Epoch 28/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1428 - accuracy: 0.9570\n",
      "Epoch 29/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1406 - accuracy: 0.9551\n",
      "Epoch 30/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1388 - accuracy: 0.9609\n",
      "Epoch 31/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1372 - accuracy: 0.9590\n",
      "Epoch 32/70\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1357 - accuracy: 0.9570\n",
      "Epoch 33/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1339 - accuracy: 0.9629\n",
      "Epoch 34/70\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1319 - accuracy: 0.9629\n",
      "Epoch 35/70\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1304 - accuracy: 0.9668\n",
      "Epoch 36/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1288 - accuracy: 0.9688\n",
      "Epoch 37/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1284 - accuracy: 0.9648\n",
      "Epoch 38/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1261 - accuracy: 0.9648\n",
      "Epoch 39/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1251 - accuracy: 0.9688\n",
      "Epoch 40/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1236 - accuracy: 0.9629\n",
      "Epoch 41/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1220 - accuracy: 0.9688\n",
      "Epoch 42/70\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1214 - accuracy: 0.9688\n",
      "Epoch 43/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1198 - accuracy: 0.9707\n",
      "Epoch 44/70\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1190 - accuracy: 0.9707\n",
      "Epoch 45/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1174 - accuracy: 0.9727\n",
      "Epoch 46/70\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1168 - accuracy: 0.9688\n",
      "Epoch 47/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1155 - accuracy: 0.9727\n",
      "Epoch 48/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1145 - accuracy: 0.9707\n",
      "Epoch 49/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1130 - accuracy: 0.9727\n",
      "Epoch 50/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1122 - accuracy: 0.9727\n",
      "Epoch 51/70\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1115 - accuracy: 0.9727\n",
      "Epoch 52/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1105 - accuracy: 0.9727\n",
      "Epoch 53/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1102 - accuracy: 0.9727\n",
      "Epoch 54/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1084 - accuracy: 0.9727\n",
      "Epoch 55/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1079 - accuracy: 0.9727\n",
      "Epoch 56/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1068 - accuracy: 0.9707\n",
      "Epoch 57/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1058 - accuracy: 0.9707\n",
      "Epoch 58/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1051 - accuracy: 0.9727\n",
      "Epoch 59/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1044 - accuracy: 0.9727\n",
      "Epoch 60/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1038 - accuracy: 0.9707\n",
      "Epoch 61/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1026 - accuracy: 0.9727\n",
      "Epoch 62/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1021 - accuracy: 0.9727\n",
      "Epoch 63/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1016 - accuracy: 0.9727\n",
      "Epoch 64/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1011 - accuracy: 0.9707\n",
      "Epoch 65/70\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1002 - accuracy: 0.9727\n",
      "Epoch 66/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0992 - accuracy: 0.9727\n",
      "Epoch 67/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0994 - accuracy: 0.9727\n",
      "Epoch 68/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0982 - accuracy: 0.9727\n",
      "Epoch 69/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0976 - accuracy: 0.9707\n",
      "Epoch 70/70\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0971 - accuracy: 0.9746\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c502debfd0>"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "ann.fit(X_train,y_train, batch_size = 32, epochs = 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ann.predict(X_test) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[35,  0],\n",
       "       [22,  0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "f1_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9824561403508771"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,f1_score,accuracy_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "Evaluating with all activation functions :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6890 - accuracy: 0.7500\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.6289\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6784 - accuracy: 0.6289\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6733 - accuracy: 0.6289\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6684 - accuracy: 0.6289\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6632 - accuracy: 0.6289\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6580 - accuracy: 0.6289\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6533 - accuracy: 0.6289\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6481 - accuracy: 0.6289\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6434 - accuracy: 0.6289\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6381 - accuracy: 0.6289\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.6289\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6277 - accuracy: 0.6309\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6222 - accuracy: 0.6309\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6167 - accuracy: 0.6328\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6108 - accuracy: 0.6328\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6047 - accuracy: 0.6367\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5980 - accuracy: 0.6465\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5913 - accuracy: 0.6504\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5836 - accuracy: 0.6602\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.6699\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5683 - accuracy: 0.6816\n",
      "Epoch 23/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.6914\n",
      "Epoch 24/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.7031\n",
      "Epoch 25/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7305\n",
      "Epoch 26/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.7402\n",
      "Epoch 27/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7422\n",
      "Epoch 28/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7637\n",
      "Epoch 29/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7812\n",
      "Epoch 30/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4986 - accuracy: 0.7969\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002C50A61B700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.6781 - accuracy: 0.6289\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.2082 - accuracy: 0.6289\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0795 - accuracy: 0.6289\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9956 - accuracy: 0.6289\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9359 - accuracy: 0.6289\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8841 - accuracy: 0.6289\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8431 - accuracy: 0.6289\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8091 - accuracy: 0.6289\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7785 - accuracy: 0.6289\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7525 - accuracy: 0.6289\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7313 - accuracy: 0.6289\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7128 - accuracy: 0.6289\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6967 - accuracy: 0.6289\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.6289\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6711 - accuracy: 0.6289\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6615 - accuracy: 0.6289\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6530 - accuracy: 0.6289\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6463 - accuracy: 0.6289\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6394 - accuracy: 0.6289\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6345 - accuracy: 0.6289\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6296 - accuracy: 0.6289\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6258 - accuracy: 0.6289\n",
      "Epoch 23/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6217 - accuracy: 0.6289\n",
      "Epoch 24/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6181 - accuracy: 0.6289\n",
      "Epoch 25/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6151 - accuracy: 0.6289\n",
      "Epoch 26/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6119 - accuracy: 0.6289\n",
      "Epoch 27/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.6289\n",
      "Epoch 28/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6053 - accuracy: 0.6289\n",
      "Epoch 29/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6018 - accuracy: 0.6289\n",
      "Epoch 30/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5983 - accuracy: 0.6289\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002C50A86E790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3455 - accuracy: 0.6289\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9206 - accuracy: 0.6289\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8079 - accuracy: 0.6289\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7504 - accuracy: 0.6289\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7115 - accuracy: 0.6289\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.6289\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6652 - accuracy: 0.6289\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6513 - accuracy: 0.6289\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6406 - accuracy: 0.6289\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6338 - accuracy: 0.6289\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6289\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6216 - accuracy: 0.6289\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6165 - accuracy: 0.6289\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6112 - accuracy: 0.6328\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6058 - accuracy: 0.6348\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6001 - accuracy: 0.6406\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5942 - accuracy: 0.6465\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5879 - accuracy: 0.6504\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.6582\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5731 - accuracy: 0.6621\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.6758\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.6875\n",
      "Epoch 23/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.6973\n",
      "Epoch 24/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.7090\n",
      "Epoch 25/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7207\n",
      "Epoch 26/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7344\n",
      "Epoch 27/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7539\n",
      "Epoch 28/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7695\n",
      "Epoch 29/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7793\n",
      "Epoch 30/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4425 - accuracy: 0.7930\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002C502F424C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Unknown activation function: leaky_relu",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-019f9668452e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mann\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#First hidden layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mann\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Second hidden layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mann\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mact\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mann\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mann\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Admin\\Desktop\\python\\Deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0munits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_initializer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitializers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Admin\\Desktop\\python\\Deeplearning\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Admin\\Desktop\\python\\Deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\activations.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(identifier)\u001b[0m\n\u001b[0;32m    527\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m     \u001b[0midentifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Admin\\Desktop\\python\\Deeplearning\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Admin\\Desktop\\python\\Deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\activations.py\u001b[0m in \u001b[0;36mdeserialize\u001b[1;34m(name, custom_objects)\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[0mdenote\u001b[0m \u001b[0many\u001b[0m \u001b[0mdefined\u001b[0m \u001b[0mTensorflow\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m   \"\"\"\n\u001b[1;32m--> 488\u001b[1;33m   return deserialize_keras_object(\n\u001b[0m\u001b[0;32m    489\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Admin\\Desktop\\python\\Deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    375\u001b[0m       \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule_objects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    378\u001b[0m             'Unknown ' + printable_module_name + ': ' + object_name)\n\u001b[0;32m    379\u001b[0m     \u001b[1;31m# Classes passed by name are instantiated with no args, functions are\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown activation function: leaky_relu"
     ]
    }
   ],
   "source": [
    "activation_functions = ['sigmoid','tanh','relu','leaky_relu','elu','preLU','softplus']\n",
    "\n",
    "data_sets123 = ['breast_cancer_data']\n",
    "\n",
    "best_activation = {}\n",
    "\n",
    "final_accuracy={}\n",
    "\n",
    "ind=0\n",
    "best_f1=-1\n",
    "\n",
    "    \n",
    "for act in activation_functions:\n",
    "    ann = tf.keras.models.Sequential()\n",
    "    ann.add(tf.keras.layers.Dense(units = 6, activation = 'relu')) #First hidden layer\n",
    "    ann.add(tf.keras.layers.Dense(units = 6, activation = 'relu')) #Second hidden layer\n",
    "    ann.add(tf.keras.layers.Dense(units = 1, activation = act))\n",
    "    ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy']) \n",
    "    ann.fit(X_train,y_train, batch_size = 32, epochs = 30)\n",
    "\n",
    "    \n",
    "    # Prediction \n",
    "\n",
    "    predicted=ann.predict(X_test) > 0.5\n",
    "\n",
    "    curr_f1 = f1_score(y_test,predicted)                   \n",
    "    #cur_f1=f1_score(y_test,predicted,average='micro')\n",
    "    #accuracy = accuracy_score(y_test,predicted)\n",
    "    accuracy = accuracy_score(y_test,predicted)\n",
    "\n",
    "    if curr_f1>best_f1:\n",
    "        best_f1=curr_f1\n",
    "        best_activation[data_sets123[ind]]=act\n",
    "        final_accuracy[data_sets123[ind]]=accuracy\n",
    "\n",
    "\n",
    "ind+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'breast_cancer_data': 'relu'}"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "best_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'breast_cancer_data': 0.7543859649122807}"
      ]
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "final_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}